{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "introduction-tensorflow",
      "graded_item_id": "d6dew",
      "launcher_item_id": "FExZ4"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "Exercise2-Question.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NapoliD/introduction-tensorflow/blob/master/Exercise2_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tOoyQ70H00_s"
      },
      "source": [
        "## Exercise 2\n",
        "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "\n",
        "I've started the code for you below -- how would you finish it? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DelVHKCw21Zl",
        "colab_type": "text"
      },
      "source": [
        "Ejercicio 2 (Traducción en Español)\n",
        "En el curso aprendiste a hacer la clasificación usando el MNIST de la moda, un conjunto de datos que contiene artículos de ropa. Hay otro conjunto de datos similar llamado MNIST que tiene artículos de escritura a mano... los dígitos del 0 al 9.\n",
        "\n",
        "Escribe un clasificador MNIST que entrene con una precisión del 99% o superior, y lo hace sin un número fijo de épocas -- es decir, deberías dejar de entrenar una vez que alcances ese nivel de precisión.\n",
        "\n",
        "Algunas notas:\n",
        "\n",
        "Debería tener éxito en menos de 10 épocas, así que está bien cambiar de épocas= a 10, pero nada más grande\n",
        "Cuando alcance el 99% o más debería imprimir la cadena \"Alcanzó el 99% de precisión, así que cancela el entrenamiento\".\n",
        "Si agregas alguna variable adicional, asegúrate de usar los mismos nombres que los usados en la clase.\n",
        "He empezado el código para ti abajo... ¿cómo lo terminarías?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7cuaz0Q2er8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9rvXQGAA0ssC",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if(logs.get('acc')>0.99):\n",
        "              print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "              self.model.stop_training = True\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    callbacks = myCallback()\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE SHOULD START HERE\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        # YOUR CODE SHOULD END HERE\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(x_train, y_train, epochs=5, callbacks=[callbacks])\n",
        "    # model fitting\n",
        "    return history.epoch, history.history['acc'][-1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VgpmF_H2esK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "43968eb0-5bc9-4378-d535-6669e569429a"
      },
      "source": [
        "train_mnist()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2032 - accuracy: 0.9402\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.0801 - accuracy: 0.9754\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0526 - accuracy: 0.9836\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0361 - accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0266 - accuracy: 0.9914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d3617ae8770d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-f3b29b540f9e>\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    }
  ]
}